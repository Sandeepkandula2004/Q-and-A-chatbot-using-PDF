# 📄 Chat with Your PDF

A Streamlit-powered RAG (Retrieval-Augmented Generation) app that lets you **upload a PDF** and **ask questions about it** using LLaMA 3 (via Groq), Chroma vector store, and HuggingFace embeddings.

---

## 🚀 Features

- 🤖 Natural language Q&A with your uploaded PDF
- 🧠 LangChain history-aware retriever
- 🔍 Chroma vector DB for semantic search
- 🧩 `llama3-8b-8192` via Groq API
- 💬 Session-based chat memory

---

## 🛠️ Requirements

- Python 3.9+
- Groq API Key → [https://console.groq.com](https://console.groq.com)
- Hugging Face Token → [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)

---

## 📦 Installation

```bash
git clone https://github.com/Sandeepkandula2004/Q-and-A-chatbot-using-PDF
cd Q-and-A-chatbot-using-PDF

# Create virtual environment
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt
```

---

## 🔐 Setup HuggingFace API Key

Set your Hugging Face API token as an environment variable before running:

### On Linux/macOS:
```bash
export HUGGINGFACE_KEY=your_huggingface_token
```

### On Windows (CMD):
```cmd
set HUGGINGFACE_KEY=your_huggingface_token
```

> 📌 **NOTE:**  
> In the original code, the line:
> ```python
> os.environ["HUGGINGFACE_KEY"] = st.secrets["HUGGINGFACE_KEY"]
> ```
> should be replaced with:
> ```python
> os.environ["HUGGINGFACE_KEY"] = os.getenv("HUGGINGFACE_KEY")
> ```
> so that the token is pulled directly from your environment during local development.

---

## ▶️ Run the App

```bash
streamlit run app.py
```

Open [http://localhost:8501](http://localhost:8501) in your browser.

---

## 🧠 How It Works

1. PDF is parsed using `PyPDFLoader`
2. Text is split using `RecursiveCharacterTextSplitter`
3. Chunks embedded using `all-MiniLM-L6-v2` from HuggingFace
4. Embeddings stored in **ChromaDB** (in a temporary folder)
5. Questions are contextualized using LangChain’s history-aware retriever
6. Answers are generated by `llama3-8b-8192` from Groq

---

## 📄 Example Questions

- "What’s the conclusion of the paper?"
- "Explain the method section briefly."
- "List any key findings mentioned."

---

## 📁 Vector Store

The vector store is saved in your temporary system directory:

```
/tmp/chroma_db  (or Windows equivalent)
```

It's re-created on each new upload.

---

## 🧩 Tech Stack

- LangChain
- Chroma
- HuggingFace Sentence Transformers
- Groq + LLaMA3
- Streamlit
